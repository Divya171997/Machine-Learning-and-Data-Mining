{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split #train_test_split helps split data into train & test set \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import tree \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV #Import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training dataset\n",
    "balance_data = pd.read_csv( \n",
    "'C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\CE802_Ass_2019_Data.csv',sep= ',') \n",
    "#import test dataset\n",
    "pred_data=pd.read_csv( \n",
    "'C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\CE802_Ass_2019_Test.csv',sep= ',') \n",
    "#import dataset by removing 20th column with nan values\n",
    "#cols = list(pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\CE802_Ass_2019_Data.csv', nrows =1))\n",
    "#balance_data = pd.read_csv( \n",
    "#'C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\CE802_Ass_2019_Data.csv',usecols =[i for i in cols if i != 'F20'],sep= ',') \n",
    "#pred_data=pd.read_csv( \n",
    "#'C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\CE802_Ass_2019_Test.csv',usecols =[i for i in cols if i != 'F20'],sep= ',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  500\n",
      "Dataset Shape:  (500, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.08</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.074146</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.074146</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.35</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>1.25</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.074146</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1  F2   F3    F4    F5    F6    F7    F8   F9  F10  ...   F12   F13  F14  \\\n",
       "0   0   0   16  2.02  0.52 -2.35 -1.98 -0.70   85    6  ... -0.07  1.08   15   \n",
       "1   0   0   86 -0.90  2.75  0.14  0.83 -0.06  107    1  ...  0.17  1.06   -8   \n",
       "2   1   1  165  0.73  1.05  0.10  2.57 -1.65   41    5  ...  0.04  0.42   -6   \n",
       "3   1   1  191 -1.50  0.79  0.33  1.24  1.35   17    2  ...  1.74  1.74   15   \n",
       "4   1   1   13  0.25 -1.19 -0.90  2.67  0.22   12    8  ... -0.39  1.25   25   \n",
       "\n",
       "    F15   F16   F17   F18   F19       F20  Class  \n",
       "0 -0.63 -3.49 -1.68  0.02  15.3  0.074146   True  \n",
       "1 -1.21  0.34  0.36  0.61  10.1  0.074146   True  \n",
       "2 -0.46 -0.62  1.67  2.60  11.0  1.550000  False  \n",
       "3  0.47  0.63  0.08  0.19   6.3  0.950000  False  \n",
       "4 -0.09 -2.41 -0.53 -0.77  10.5  0.074146   True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values in training dataset\n",
    "balance_data['F20'].fillna(balance_data['F20'].mean())\n",
    "balance_data=balance_data.fillna(balance_data.mean())\n",
    "\n",
    "\n",
    "#missing values in test dataset\n",
    "pred_data['F20'].fillna(pred_data['F20'].mean())\n",
    "pred_data=pred_data.fillna(pred_data.mean())\n",
    "\n",
    "#dataset shape\n",
    "print(\"Length: \", len(balance_data)) \n",
    "print(\"Dataset Shape: \", balance_data.shape)\n",
    "\n",
    "#dataset observation\n",
    "balance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data slicing \n",
    "X = balance_data.values[:,:-1]\n",
    "Y = balance_data.values[:,20]\n",
    "\n",
    "#cutomized code to convert response variable in 0 and 1 for the use in algorithm\n",
    "for i in range (Y.size):\n",
    "    if Y[i]:\n",
    "        Y[i] = 1\n",
    "    else:\n",
    "        Y[i] = 0\n",
    "Y=Y.astype(int)\n",
    "\n",
    "X_pred=pred_data.values[:,0:20]\n",
    "\n",
    "#split the dataset into 70% training and 30% testing set \n",
    "X_train, X_validate, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "  [[70 11]\n",
      " [55 14]]\n",
      "Accuracy :  56.00000000000001\n",
      "Precision: 56.00000000000001\n",
      "Recall: 20.28985507246377\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.86      0.68        81\n",
      "           1       0.56      0.20      0.30        69\n",
      "\n",
      "    accuracy                           0.56       150\n",
      "   macro avg       0.56      0.53      0.49       150\n",
      "weighted avg       0.56      0.56      0.50       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######Decision tree pruning #########\n",
    "#Creating decision tree classifier object with gini index\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 0, \n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "#Perform Training\n",
    "clf_gini.fit(X_train, y_train)\n",
    "\n",
    "#Pridiction on test set with gini index\n",
    "y_pred = clf_gini.predict(X_validate)\n",
    "#print(y_pred)\n",
    "\n",
    "#Calculating Test set Accuracy with gini index\n",
    "print(\"Confusion Matrix:\\n \",confusion_matrix(y_test, y_pred))  \n",
    "print (\"Accuracy : \",accuracy_score(y_test,y_pred)*100)  \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)*100) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)*100)\n",
    "print(\"Report : \\n\",classification_report(y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "  [[70 11]\n",
      " [53 16]]\n",
      "Accuracy:  57.333333333333336\n",
      "Precision: 59.25925925925925\n",
      "Recall: 23.18840579710145\n",
      "Report :\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        81\n",
      "           1       0.59      0.23      0.33        69\n",
      "\n",
      "    accuracy                           0.57       150\n",
      "   macro avg       0.58      0.55      0.51       150\n",
      "weighted avg       0.58      0.57      0.52       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating decision tree classifier object with information gain \n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, \n",
    " max_depth=3, min_samples_leaf=5) \n",
    "\n",
    "#Perform Training\n",
    "clf_entropy.fit(X_train, y_train) \n",
    "\n",
    "#Pridiction on test set with information gain \n",
    "y_pred_en = clf_entropy.predict(X_validate)\n",
    "#print(y_pred_en)\n",
    "\n",
    "#Calculating Test set Accuracy with information gain \n",
    "print(\"Confusion Matrix: \\n \",  \n",
    "      confusion_matrix(y_test,y_pred_en))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred_en)*100) \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_en)*100) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_en)*100)\n",
    "print(\"Report :\\n \",classification_report(y_test,y_pred_en)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 0, 'splitter': 'best'}\n",
      "Best CV accuracy:  59.14285714285714\n",
      "Best hyerparameters:  {'max_depth': 3, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Accuracy of best model  57.333333333333336\n"
     ]
    }
   ],
   "source": [
    "#Results of both criteria are nearly same\n",
    "#Difficult to choose which is better\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "#print hyperparameters  \n",
    "print(clf_gini.get_params()) \n",
    "\n",
    "#pruning with Grid search CV \n",
    "#Defining grid of hyperparameters \n",
    "parameter_grid = { \n",
    "'max_depth': [1,3,5,7,9,20], \n",
    "'min_samples_split': [2,3, 4, 5], \n",
    "'min_impurity_decrease': [0.01 , 0.012,0.004 , 0.008], \n",
    "'min_samples_leaf':[2,5,6,8,10] \n",
    "}\n",
    "\n",
    "# Instantiate a 10-fold CV grid search object 'grid' \n",
    "grid = GridSearchCV(estimator=clf_gini, \n",
    "                       param_grid=parameter_grid, \n",
    "                       scoring='accuracy', \n",
    "                       cv=10) \n",
    "# Fit grid to the training set. \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# Best CV score across all parameters from 'grid' \n",
    "print('Best CV accuracy: ',format(grid.best_score_*100))\n",
    "\n",
    "#Best hyperparameters   \n",
    "print('Best hyerparameters: ', grid.best_params_ )\n",
    "\n",
    "\n",
    "#Best Estimator\n",
    "best_model = grid.best_estimator_ \n",
    "# Calculate accuracy \n",
    "print(\"Accuracy of best model \",format(best_model.score(X_validate,y_test)*100))\n",
    "#Accuracy is same as entropy criterion.So,precision and recall is same as information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "  [[63 18]\n",
      " [37 32]]\n",
      "Accuracy: 63.33333333333333\n",
      "Precision: 64.0\n",
      "Recall: 46.3768115942029\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classification \n",
    "#import required libraries \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "from sklearn import metrics # import the metrics class \n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression() \n",
    "# fit the model with training data \n",
    "logreg.fit(X_train,y_train) \n",
    "#predicting with test set \n",
    "y_pred_reg=logreg.predict(X_validate) \n",
    "\n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "print(\"Confusion Matrix: \\n \",confusion_matrix(y_test,y_pred_reg))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_reg)*100) \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_reg)*100) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_reg)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "  [[68 13]\n",
      " [39 30]]\n",
      "Accuracy: 65.33333333333333\n",
      "Precision: 69.76744186046511\n",
      "Recall: 43.47826086956522\n"
     ]
    }
   ],
   "source": [
    "# import support vector classifier \n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "supp_vector = SVC(kernel='linear')\n",
    "# instantiate the model (using the default parameters)  \n",
    "# fit the model with data \n",
    "supp_vector.fit(X_train,y_train) \n",
    "#predicting with test set \n",
    "y_pred_svc=supp_vector.predict(X_validate) \n",
    "\n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "print(\"Confusion Matrix: \\n \",confusion_matrix(y_test,y_pred_svc))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_svc)*100) \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_svc)*100) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_svc)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "  [[62 19]\n",
      " [47 22]]\n",
      "Accuracy: 56.00000000000001\n",
      "Precision: 53.65853658536586\n",
      "Recall: 31.88405797101449\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classification\n",
    "# training the model on training set\n",
    "\n",
    "#import library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#This library already included in the beginning\n",
    "from sklearn import metrics \n",
    "\n",
    "#instantiate the model\n",
    "gnb = GaussianNB() \n",
    "\n",
    "#fit the model with data \n",
    "gnb.fit(X_train,y_train) \n",
    "  \n",
    "# making predictions on the testing set \n",
    "y_pred_bayes = gnb.predict(X_validate) \n",
    "  \n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "print(\"Confusion Matrix: \\n \",confusion_matrix(y_test,y_pred_bayes))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_bayes)*100) \n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_bayes)*100) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_bayes)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  359\n",
      "1:  141\n"
     ]
    }
   ],
   "source": [
    "#Support Vector is the best algorithm among four.\n",
    "best_y_pred=supp_vector.predict(X_pred)\n",
    "\n",
    "#Converting class integer values into boolean values\n",
    "a=0\n",
    "b=0\n",
    "for i in best_y_pred: \n",
    "    if i==0: \n",
    "        best_y_pred[i] = True \n",
    "        a=a+1\n",
    "    else: \n",
    "        best_y_pred[i] = False\n",
    "        b=b+1\n",
    "best_y_pred = best_y_pred.astype(bool)\n",
    "\n",
    "#Printing total number of '0' and '1' in predicted outcome\n",
    "print(\"0: \",a) \n",
    "print(\"1: \",b)       \n",
    "\n",
    "#fill the predicted results in test csv.\n",
    "#import the test dataset\n",
    "#fill the predicted class in test dataset\n",
    "pred_data['Class'] = best_y_pred\n",
    "pred_data['Class'] = pred_data['Class']\n",
    "\n",
    "#Form csv file of predicted results\n",
    "pred_data.to_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\coursework ml\\\\New folder\\\\New_Version_CE802_Ass_2019_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coding help taken from these websites\\nDecision tree:\\nhttps://www.geeksforgeeks.org/decision-tree-implementation-python/\\nhttps://www.ritchieng.com/machine-learning-decision-trees/\\n\\nLogistic Regression:\\nhttps://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\\n\\nSupport Vector:\\nhttps://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-python/\\n\\nNaive Bayes:\\nhttps://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\\n\\nMissing value:\\nhttps://jamesrledoux.com/code/imputation\\n\\nCSV:https:\\n//stackoverflow.com/questions/34864695/saving-prediction-results-to-csv '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Coding help taken from these websites\n",
    "Decision tree:\n",
    "https://www.geeksforgeeks.org/decision-tree-implementation-python/\n",
    "https://www.ritchieng.com/machine-learning-decision-trees/\n",
    "\n",
    "Logistic Regression:\n",
    "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "\n",
    "Support Vector:\n",
    "https://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-python/\n",
    "\n",
    "Naive Bayes:\n",
    "https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "\n",
    "Missing value:\n",
    "https://jamesrledoux.com/code/imputation\n",
    "\n",
    "CSV:https:\n",
    "//stackoverflow.com/questions/34864695/saving-prediction-results-to-csv \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
